{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40a1b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.util import ngrams\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ab7cb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "input_file = 'Training_Essay_Data.csv'\n",
    "\n",
    "df = pd.read_csv(input_file)\n",
    "data = df.sample(n=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54455b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17004    would agree emersons world important things co...\n",
      "14459    advice wonderful helpful everyone since people...\n",
      "28492    think limiting car usage great environment lot...\n",
      "10134    nobody know face got mars never face could jum...\n",
      "23657    student studied lot subjects school stage hesh...\n",
      "Name: processed_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Join tokens back into text\n",
    "    processed_text = ' '.join(tokens)\n",
    "    return processed_text\n",
    "\n",
    "# Preprocess text data\n",
    "data['processed_text'] = data['text'].apply(preprocess_text)\n",
    "\n",
    "print(data['processed_text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aacdd8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 47202\n"
     ]
    }
   ],
   "source": [
    "# Tokenization and vocabulary building\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data['processed_text'])\n",
    "\n",
    "# Get the vocabulary\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(\"Vocabulary size:\", len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89a42818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   aa  aaa  aaaeal  aaccording  aactive  aafetoy  aagain  aaid  aake  aaken  \\\n",
      "0   0    0       0           0        0        0       0     0     0      0   \n",
      "1   0    0       0           0        0        0       0     0     0      0   \n",
      "2   0    0       0           0        0        0       0     0     0      0   \n",
      "3   0    0       0           0        0        0       0     0     0      0   \n",
      "4   0    0       0           0        0        0       0     0     0      0   \n",
      "\n",
      "   ...  zooming  zoos  zroom  zs  zuckerberg  zuckerburg  zygomatic  \\\n",
      "0  ...        0     0      0   0           0           0          0   \n",
      "1  ...        0     0      0   0           0           0          0   \n",
      "2  ...        0     0      0   0           0           0          0   \n",
      "3  ...        0     0      0   0           0           0          0   \n",
      "4  ...        0     0      0   0           0           0          0   \n",
      "\n",
      "   zygomatice  zygosmtic  zzzzs  \n",
      "0           0          0      0  \n",
      "1           0          0      0  \n",
      "2           0          0      0  \n",
      "3           0          0      0  \n",
      "4           0          0      0  \n",
      "\n",
      "[5 rows x 47202 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the BoW matrix to a DataFrame for better visualization\n",
    "bow_df = pd.DataFrame(X.toarray(), columns=vocab)\n",
    "\n",
    "print(bow_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccfbf0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, data['generated'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe4eff18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (8000, 47202)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a0ba75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saniddha Ghosh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "155c2472",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33549cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.988\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a5a9983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e980031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = SVC(kernel='linear') \n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75e0be2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.985\n"
     ]
    }
   ],
   "source": [
    "y_pred_SVM = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f4666ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "359d2729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1198\n",
      "           1       0.98      0.99      0.99       802\n",
      "\n",
      "    accuracy                           0.99      2000\n",
      "   macro avg       0.99      0.99      0.99      2000\n",
      "weighted avg       0.99      0.99      0.99      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd0d03b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the text to predict: \n",
      "  @media print {\n",
      "    .ms-editor-squiggles-container {\n",
      "      display:none !important;\n",
      "    }\n",
      "  }\n",
      "  .ms-editor-squiggles-container {\n",
      "    all: initial;\n",
      "  }America's love of cars may soon be spiraling down. With America's car culture seemingly coming to an end, there will be more alternative ways to get to work, school, shopping districts, and etc. As the years come and go by quickly, Americans are buying less cars and obtaining fewer licenses for themselves. The advantages we can recieve by limiting our car usage is that it takes away stress, lowers air pollution, and benefits daily businesses.  First, Limiting car usage takes away stress. As businessman Carlos Arturo Plaza states:\"It's a good opportunity to take away stress...\"Â  People who no longer own a car will not have to worry as much about their car. Such as the price of gas rising, car payments, and insurance payments. These type of payments every month often put a big dent in a person's wallet. If we take up to the oppurtunity of limiting our car usage, we really won't have to worry about car payments anymore. Plus, being outside in the environment will certainly reduce stress levels almost completely, because we are interacting with others that are waliking and enjoying the the environment outside.  In addition to, taking away stress. Limiting car usage will result in lower air pollution. According to Duffer, \"Congestion was down 60 percent in the capital of France, after five-days of intensifying smog...\" If we limit car usage, the levels of air pollution will dramatically decrease resulting in cleaner air and a healthy environment for us to live in. If we continue to use cars, we are further damaging the air that we breathe everyday and causing people to damage their lungs. Pollution often has chemicals that can harm our breathing and sometimes our lungs. As Americans it is our responsibility to take care of the earth and we are not doing so by constently using our cars.  Lastly, limiting car usage benefits daily businesses. Selsky staes: \"Parks and sport centers also have bloomed throughout the city; and new restaurants and upscale shopping districts have cropped up. If we rely on walking to stores, etc. that are only a block away, it will surely increase the revunue of restaurants and shopping districts. Since the stores are so close to home, we'll be more willing to enter the store and/or restaurant. Increasing businesses revunue also helps the economy, which we desperately need.  In conclusion, these advantages that we have gone over in the essay will greatly impact the future of America. Such as,Â  taking away stress from former car owners, lowering the air pollution so we have a cleaner air to breathe, and beneifiting our daily businesses to increase revunue and better our economy. If we all limit car usage and follow the advantages listed, it will result in a better earth for us to live in.\n"
     ]
    }
   ],
   "source": [
    "input_text = input(\"Enter the text to predict: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e70b90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the input text\n",
    "input_vec = vectorizer.transform([input_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54cb7451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make prediction\n",
    "predicted_label = model.predict(input_vec)\n",
    "predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947654f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
